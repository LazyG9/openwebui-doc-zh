---
sidebar_position: 400
title: "⭐ 功能特性"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的主要功能特性 ⭐

- 🚀 **轻松部署**：使用 Docker 或 Kubernetes（`kubectl`、`kustomize` 或 `helm`）无缝安装，提供无忧体验，支持包含 Ollama 的 `:ollama` 镜像和支持 CUDA 的 `:cuda` 镜像。

- 🤝 **OpenAI API 集成**：轻松集成 OpenAI 兼容的 API，实现与 Ollama 模型并行的多样化对话。OpenAI API URL 可以自定义，以连接各种第三方应用。

- 🛡️ **细粒度权限和用户组**：通过允许管理员创建详细的用户角色和权限，我们确保了安全的用户环境。这种细粒度不仅增强了安全性，还允许定制用户体验，培养用户的所有权和责任感。

- 📱 **响应式设计**：在台式电脑、笔记本和移动设备上享受无缝体验。

- 📱 **移动端渐进式 Web 应用**：在 `localhost` 或个人域名上享受离线访问的原生渐进式 Web 应用体验，以及流畅的用户界面。为了使我们的 PWA 可以在您的设备上安装，它必须在安全的环境中提供。这通常意味着它必须通过 HTTPS 提供服务。
  - 要设置 PWA，您需要了解 Linux、Docker 和反向代理（如 `Nginx`、`Caddy` 或 `Traefik`）等技术。使用这些工具可以帮助简化构建和部署符合您需求的 PWA 的过程。虽然没有"一键安装"选项，而且通过 HTTPS 安全部署 Open WebUI 实例的可用选项需要用户经验，但使用这些资源可以使创建和部署符合您需求的 PWA 变得更容易。

- ✒️🔢 **完整的 Markdown 和 LaTeX 支持**：通过全面的 Markdown 和 LaTeX 功能提升您的 LLM 体验，实现丰富的交互。

- 🧩 **模型构建器**：直接在 Open WebUI 中轻松创建 Ollama 模型。通过 [Open WebUI Community](https://openwebui.com/) 集成，创建和添加自定义角色和代理，自定义聊天元素，轻松导入模型。

- 📚 **本地和远程 RAG 集成**：通过我们在聊天中的前沿检索增强生成（RAG）技术，深入探索您的文档。文档可以加载到工作区，之后可以使用查询前的 `#` 符号访问，或者通过以 `#` 开头的提示词，后跟 URL 进行网页内容集成。

- 🔍 **RAG 的网页搜索**：您可以使用各种搜索提供商进行网页搜索，并将结果直接注入到本地检索增强生成（RAG）体验中。

- 🌐 **网页浏览功能**：通过使用 `#` 命令后跟 URL，将网站无缝集成到您的聊天体验中。此功能使网页内容可以直接整合到您的对话中，从而增强交互的丰富性和深度。

- 🎨 **图像生成集成**：无缝整合图像生成功能，用动态视觉内容丰富您的聊天体验。

- ⚙️ **并发模型使用**：轻松同时使用多个模型，利用它们的独特优势获得最佳响应。并行利用多种模型模态来增强您的体验。

- 🔐 **基于角色的访问控制（RBAC）**：通过受限权限确保安全访问。只有授权人员可以访问您的 Ollama，而模型创建和拉取权限仅限于管理员。

- 🌐🌍 **多语言支持**：通过我们的国际化（`i18n`）支持，以您喜欢的语言体验 Open WebUI。我们邀请您加入我们，扩展我们支持的语言！我们正在积极寻找贡献者！

- 🌟 **持续更新**：我们致力于通过定期更新、修复和新功能来改进 Open WebUI。

## 以及更多令人瞩目的功能，包括... ⚡️

---

### 🔧 管道支持

- 🔧 **管道框架**：通过我们的模块化插件框架无缝集成和自定义您的 Open WebUI 体验，增强定制性和功能性（https://github.com/open-webui/pipelines）。我们的框架允许轻松添加自定义逻辑和集成 Python 库，从 AI 代理到家庭自动化 API。

- 📥 **上传管道**：可以直接从`管理面板` > `设置` > `管道`菜单上传管道，简化管道管理过程。

#### 我们的管道框架的可能性无限，几乎没有界限。从一些预构建的管道开始，帮助您入门！

- 🔗 **函数调用**：通过管道无缝集成[函数调用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，通过高级函数调用功能增强您的 LLM 交互。

- 📚 **自定义 RAG**：无缝集成[自定义检索增强生成（RAG）](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag)管道，通过自定义 RAG 逻辑增强您的 LLM 交互。

- 📊 **使用 Langfuse 监控消息**：通过 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 管道实时监控和分析消息交互的使用统计。

- ⚖️ **用户速率限制**：通过控制发送到 LLM 的请求流量来有效管理 API 使用，防止超过速率限制，使用[速率限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py)管道。

- 🌍 **实时 LibreTranslate 翻译**：使用 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 管道将实时翻译集成到您的 LLM 交互中，实现跨语言通信。
  - 请注意，此管道需要在 Docker 容器中进一步设置 LibreTranslate 才能工作。

- 🛡️ **有毒消息过滤**：我们的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 管道自动过滤有毒消息，维护干净安全的聊天环境。

- 🔒 **LLM-Guard**：通过 [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 管道确保 LLM 交互的安全性，具有提示注入扫描器功能，可检测和缓解针对大型语言模型的巧妙输入操作。这可以保护您的 LLM 免受数据泄漏，并增加对提示注入攻击的抵抗层。

- 🕒 **对话轮次限制**：通过[对话轮次限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py)管道设置对话轮次限制，改善交互管理。

- 📈 **OpenAI 生成统计**：我们的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 管道为 OpenAI 模型提供详细的生成统计信息。

- **🚀 多模型支持**：我们与[各种提供商](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers)的 AI 模型的无缝集成扩展了您的可能性，提供广泛的语言模型供选择和交互。

#### 除了广泛的功能和自定义选项外，我们还提供[一个可直接使用的示例管道库](https://github.com/open-webui/pipelines/tree/main/examples)以及[一个实用的示例脚手架管道](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py)来帮助您入门。这些资源将简化您的开发过程，使您能够快速使用管道和 Python 创建强大的 LLM 交互。祝您编码愉快！💡

---

### 🖥️ 用户体验

- 🖥️ **直观界面**：聊天界面设计时考虑了用户，灵感来自 ChatGPT 的用户界面。

- ⚡ **快速响应**：享受可靠快速响应性能。

- 🎨 **启动画面**：简单的启动画面，以获得更好的用户体验。

- 📦 **pip 安装方法**：可以通过命令 `pip install open-webui` 安装 Open WebUI，简化过程并使新用户更容易访问。有关更多信息，请访问：https://pypi.org/project/open-webui/。

- 🌈 **主题定制**：通过一系列选项个性化您的 Open WebUI 体验，包括各种纯色、简洁的主题、可定制的聊天背景图像和三种模式选项：亮色、暗色或 OLED 暗色 - 或让 *Her* 为您选择！ ;)

- 💻 **代码语法高亮**：我们的语法高亮功能增强了代码的可读性，提供清晰的代码视图。

- ↕️ **双向聊天支持**：您可以轻松地在左到右和右到左聊天方向之间切换，以适应各种语言偏好。

- 📱 **移动设备访问**：可以在移动设备上打开和关闭侧边栏，只需简单地滑动即可。

- 📂 **统一工作区**：统一工作区部分提供对所有模型文件、提示词、文档、工具和功能的访问，简化工作流程。

- 💾 **持久设置**：通过保存和持久设置，从 Open WebUI 中受益，存储在 config.json 文件中，便于访问和重用。

- ❓ **快速访问文档和快捷键**：主 UI 屏幕右下角的问题按钮（在桌面电脑和笔记本电脑上可用）提供用户访问 Open WebUI 文档页面和可用键盘快捷键的便捷方式。

- 📜 **更改日志和检查更新**：用户可以在`设置` > `关于` > `查看新功能`菜单中访问全面的更改日志和检查更新，提供最新功能、改进和错误修复的快速概览，以及检查更新的能力。

---

### 💬 对话

- 🔍 **RAG 嵌入支持**：直接在 `管理面板` > `设置` > `文档`菜单中更改检索增强生成（RAG）嵌入模型，增强文档处理。此功能支持 Ollama 和 OpenAI 模型。

- 📜 **RAG 功能中的引用**：检索增强生成（RAG）功能允许用户轻松跟踪向 LLM 提供文档的上下文，并添加引用以参考点。

- 🌟 **增强的 RAG 管道**：一个可切换的混合搜索子功能，用于我们的 RAG 嵌入功能，通过 `BM25` 增强 RAG 功能，由 `CrossEncoder` 提供动力，并可配置相关性分数阈值。

- 📹 **YouTube RAG 管道**：通过视频 URL 为总结 YouTube 视频而专门设计的检索增强生成（RAG）管道，实现与视频字幕的流畅交互。

- 🔄 **多模态支持**：轻松与支持多模态交互的模型互动，包括图像（例如，LLaVA）。

- 🤖 **多模型支持**：快速在不同的模型之间切换，以进行不同的聊天交互。

- 👥 **'@' 模型集成**：通过在对话中无缝切换到任何可访问的本地或外部模型，用户可以利用多个模型的集体智能，在单个对话中完成此操作。可以通过使用 `@` 命令指定模型名称来完成此操作。

- 🏷️ **对话标记**：轻松分类和定位标记对话，以便快速参考和简化数据收集。

- 👶 **对话克隆**：轻松克隆和保存任何对话的快照，以便将来参考或继续。此功能使您可以轻松地从上次中断的地方继续或与他人分享您的会话。要创建对话的副本，只需单击对话的下拉选项中的 `克隆` 按钮。你能跟上你的克隆吗？

- 📜 **提示词预设支持**：通过聊天输入中的 `/` 命令，立即访问自定义提示词。加载预定义的对话启动器，轻松快捷地进行交互。通过 [Open WebUI Community](https://openwebui.com/) 集成或创建自己的提示词。

- 📅 **提示词变量支持**：提示词变量，如 `{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}` 和 `{{USER_LOCATION}}`，可以在系统提示词中使用或通过使用斜杠命令选择提示词直接在聊天中使用。
  - 请注意，`{{USER_LOCATION}}` 提示词变量需要通过 HTTPS 的安全连接。要使用此特定提示词变量，请确保从 `设置` > `界面` 菜单中将 `{{USER_LOCATION}}` 切换为开。
  - 请注意，`{{CLIPBOARD}}` 提示词变量需要访问您的设备剪贴板。

- 🧠 **记忆功能**：通过 `设置` > `个性化` > `记忆` 菜单手动添加您希望 LLM 记住的信息。记忆可以添加、编辑和删除。

---

### 💻 模型管理

- 🛠️ **模型构建器**：所有模型都可以通过模型工作区中的持久模型构建器模式进行构建和编辑。

- 📚 **模型知识支持**：可以从模型工作区直接将函数和文档附加到模型，增强每个模型的可用信息。

- 🗂️ **模型预设**：为 Ollama 和 OpenAI API 创建和管理模型预设。

- 🏷️ **模型标记**：模型工作区允许用户使用标记组织他们的模型。

- 📋 **模型选择器下拉排序**：可以通过在模型工作区中拖放模型来轻松组织它们，这些更改会反映在模型下拉菜单中。

- 🔍 **模型选择器下拉菜单**：通过包含搜索过滤器和详细的模型信息（包括模型标签和描述），轻松找到和选择您的模型。

- ⚙️ **高级参数精细控制**：通过调整模型参数（如 `seed`、`temperature`、`frequency penalty`、`context length`、`seed` 等）获得更深层次的控制。

- 🔄 **无缝集成**：直接从 [Ollama 库](https://ollama.com/library/) 的模型页面复制任何 `ollama run {model:tag}` CLI 命令，并将其粘贴到模型下拉菜单中，轻松选择和拉取模型。

- 🗂️ **创建 Ollama Modelfile**：要为 Ollama 创建模型文件，请导航到 `管理面板` > `设置` > `模型` > `创建模型` 菜单。

- ⬆️ **GGUF 文件模型创建**：通过从 Open WebUI 直接上传 GGUF 文件，从 `管理设置` > `设置` > `模型` > `实验` 菜单中轻松创建 Ollama 模型。该过程已通过从您的机器上传或从 Hugging Face 下载 GGUF 文件的选项进行优化。

- ⚙️ **默认模型设置**：新聊天的默认模型偏好可以在移动设备上的 `设置` > `界面` 菜单中设置，或者在桌面电脑和笔记本电脑上通过模型选择器下拉菜单更轻松地设置。

- 💡 **LLM 响应洞察**：可以查看每个生成响应的详细信息，包括外部模型 API 洞察和全面的本地模型信息。

- 📥🗑️ **下载/删除模型**：可以直接从 Open WebUI 轻松下载或删除模型。

- 🔄 **更新所有 Ollama 模型**：通过一次操作方便地更新所有本地安装的模型，简化模型管理。

- 🍻 **TavernAI 角色卡集成**：在我们的模型构建器中体验增强的视觉叙事，通过 TavernAI 角色卡集成。用户可以将 TavernAI 角色卡 PNG 无缝地直接集成到他们的模型文件中，创造更加身临其境和引人入胜的用户体验。

- 🎲 **模型游乐场（测试版）**：通过模型游乐场区域（测试版）尝试模型，用户可以在沙盒环境中轻松测试和探索模型功能和参数，然后再部署到实时聊天环境中。

---

### 👥 协作

- 🗨️ **本地聊天共享**：通过生成和共享聊天链接，在用户之间高效无缝地进行协作和沟通。

- 👍👎 **RLHF 标注**：通过点赞或点踉来增强您的消息影响力，并可选择提供文本反馈，便于创建人类反馈强化学习（`RLHF`）数据集。利用您的消息来训练或微调模型，同时确保本地保存数据的机密性。

- 🤝 **社区共享**：通过点击 `分享到 Open WebUI 社区` 按钮，将您的聊天会话分享到 [Open WebUI Community](https://openwebui.com/)。此功能允许您与其他用户互动并在平台上协作。
  - 要使用此功能，请登录您的 Open WebUI Community 账户。分享您的聊天可以培养充满活力的社区，鼓励知识共享，并促进联合问题解决。请注意，聊天会话的社区共享是一个可选功能。只有管理员可以在 `管理设置` > `设置` > `常规` 菜单中打开或关闭此功能。

---

### 📚 历史记录和归档

- 📜 **聊天历史**：通过聊天导航侧边栏轻松访问和管理您的对话历史。在 `设置` > `聊天` 菜单中关闭聊天历史，以防止在新的交互中创建聊天历史。

- 🔄 **重新生成历史访问**：轻松重访和探索您的完整 LLM 响应重新生成历史。

- 📬 **归档聊天**：轻松存储您与模型的已完成对话，以供将来参考或交互，保持整洁和无杂乱的聊天界面。

- 🗃️ **归档所有聊天**：此功能允许您一次性快速归档所有聊天。

- 📦 **导出所有归档聊天为 JSON**：此功能使用户能够轻松地将所有归档聊天导出为单个 JSON 文件，可用于备份或传输目的。

- 📄 **下载聊天为 JSON/PDF/TXT**：轻松以您偏好的 `.json`、`.pdf` 或 `.txt` 格式单独下载您的聊天。

- 📤📥 **导入/导出聊天历史**：通过 `导入聊天` 和 `导出聊天` 选项，无缝地将您的聊天数据移入和移出平台。

- 🗑️ **删除所有聊天**：此选项允许您永久删除所有聊天，确保全新的开始。

---

### 🎙️ 语音和无障碍

- 🗣️ **语音输入支持**：通过语音交互与您的模型互动；享受直接与模型对话的便利。此外，探索在 3 秒静音后自动发送语音输入的选项，实现流畅的体验。
  - 麦克风访问需要手动设置通过 HTTPS 的安全连接才能工作，或者[自行承担风险手动将您的 URL 加入白名单](https://docs.openwebui.com/troubleshooting/microphone-error)。

- 😊 **表情符号通话**：从 `设置` > `界面` 菜单打开此功能，允许 LLM 在语音通话期间使用表情符号表达情感，实现更加动态的交互。
  - 此功能需要通过 HTTPS 的安全连接才能访问麦克风。

- 🎙️ **免提语音通话功能**：无需使用手即可发起语音通话，使交互更加无缝。
  - 此功能需要通过 HTTPS 的安全连接才能访问麦克风。

- 📹 **视频通话功能**：与支持视觉的模型（如 LlaVA 和 GPT-4o）启用视频通话，为您的通信添加视觉维度。
  - 此功能需要通过 HTTPS 的安全连接才能同时访问摄像头和麦克风。

- 👆 **点击中断**：在移动设备上通过简单的点击停止 AI 的语音，确保对交互的无缝控制。

- 🔊 **可配置文本转语音端点**：通过可配置的 OpenAI 兼容端点自定义您的文本转语音体验，用于朗读 LLM 响应。

---

### 🐍 代码执行

- 🚀 **多功能、UI 无关、OpenAI 兼容的插件框架**：无缝集成和自定义 [Open WebUI Pipelines](https://github.com/open-webui/pipelines) 以实现高效的数据处理和模型训练，确保最大的灵活性和可扩展性。

- 🛠️ **原生 Python 函数调用**：通过原生函数调用直接在 Open WebUI 中访问 Python 的强大功能。通过内置代码编辑器轻松集成自定义代码，在 `工具` 和 `函数` 工作区中构建独特功能，如自定义 RAG 管道、网页搜索工具，甚至类似代理的操作。

- 🐍 **Python 代码执行**：通过 Pyodide 在浏览器中本地执行 Python 代码，支持 Pyodide 支持的各种库。

- 🌊 **Mermaid 渲染**：使用 [Mermaid 图表和制图工具](https://mermaid.js.org/intro/) 直接在 Open WebUI 中创建视觉吸引力的图表和流程图，支持 Mermaid 语法渲染。

---

### 🔒 集成和安全

- ✨ **多个 OpenAI 兼容 API 支持**：无缝集成和自定义各种 OpenAI 兼容的 API，增强聊天交互的多样性。

- 🔑 **简化的 API 密钥管理**：轻松生成和管理密钥，以便使用 OpenAI 库利用 Open WebUI，简化集成和开发。

- 🌐 **HTTP/S 代理支持**：使用 `http_proxy` 或 `https_proxy` 环境变量轻松配置网络设置。如果设置了这些变量，它们应该包含 HTTP 和 HTTPS 代理的 URL。

- 🌐🔗 **外部 Ollama 服务器连接**：通过配置环境变量，无缝链接到托管在不同地址的外部 Ollama 服务器。

- 🛢️ **外部数据库支持**：使用 `DATABASE_URL` 环境变量无缝连接到自定义 SQLite 或 Postgres 数据库。

- 🌐🗣️ **外部语音转文本支持**：添加外部语音转文本（`STT`）服务提供增强的灵活性，允许用户选择他们偏好的提供商以实现无缝交互。

- 🌐 **远程 ChromaDB 支持**：通过连接到远程 ChromaDB 服务器扩展您的数据库功能。

- 🔀 **多个 Ollama 实例负载均衡**：轻松地在多个 Ollama 实例之间分配聊天请求，以提高性能和可靠性。

---

### 👑 管理

- 👑 **超级管理员分配**：自动将第一个注册用户分配为超级管理员，其角色不可更改，即使是其他管理员也无法修改。

- 🛡️ **细粒度用户权限**：通过可自定义的基于角色的权限限制用户操作和访问，确保只有授权人员才能执行特定任务。

- 👥 **多用户管理**：带有分页的直观管理面板，允许您无缝管理多个用户，简化用户管理和用户生命周期管理。

- 🔧 **管理面板**：用户管理系统旨在简化用户的加入和管理，提供直接添加用户或通过 CSV 导入批量添加用户的选项。

- 👥 **活跃用户指示器**：监控活跃用户数量以及谁在使用哪些模型，以帮助判断何时可能由于用户数量过多而影响性能。

- 🔒 **默认注册角色**：为新注册用户指定默认角色为 `待定`、`用户` 或 `管理员`，为新用户提供灵活的权限和访问级别管理。

- 🔒 **阻止新注册**：启用禁用新用户注册的选项，限制平台访问并维持固定的用户数量。

- 🔒 **阻止聊天删除**：管理员可以切换设置，阻止所有用户删除他们的聊天消息，确保所有聊天消息都保留用于审计或合规目的。

- 🔗 **Webhook 集成**：通过 webhook（兼容 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams`）订阅新用户注册事件，提供实时通知和自动化功能。

- 📣 **可配置通知横幅**：管理员可以在 config.json 中创建可持久化的自定义横幅，具有内容、背景颜色（`info`、`warning`、`error` 或 `success`）和可关闭性选项。横幅仅对已登录用户可见，确保敏感信息的机密性。

- 🛡️ **模型白名单**：通过允许管理员为具有 `user` 角色的用户设置模型白名单，增强安全性和访问控制，确保只能访问授权的模型。

- 🔑 **社区共享的管理控制**：管理员可以通过 `管理面板` > `设置` 菜单中的开关为所有用户启用或禁用社区共享。此开关允许管理员管理可访问性和隐私，确保安全的环境。管理员可以选择为所有用户启用或禁用 `分享到社区` 按钮，从而控制社区参与和协作。

- 📧 **可信电子邮件认证**：可选择使用可信电子邮件头部进行认证，为您的 Open WebUI 实例添加额外的安全和认证层。

- 🔒 **后端反向代理支持**：通过 Open WebUI 的后端与 Ollama 之间的直接通信加强安全性。这个关键功能消除了在局域网（LAN）上暴露 Ollama 的需求。从 Open WebUI 发送到 `/ollama/api` 路由的请求会从后端无缝重定向到 Ollama，增强整体系统安全性并提供额外的保护层。

- 🔒 **认证**：请注意，Open WebUI 本身不支持联合认证方案，如 SSO、OAuth、SAML 或 OIDC。但是，它可以配置为将认证委托给认证反向代理，有效实现单点登录（`SSO`）体验。此设置允许您集中用户认证和管理，增强安全性和用户便利性。通过将 Open WebUI 与认证反向代理集成，您可以利用现有的认证系统并简化用户对 Open WebUI 的访问。有关配置此功能的更多信息，请参阅[联合身份认证支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可选认证**：通过将 `WEBUI_AUTH` 设置为 `False` 享受禁用认证的灵活性。这是没有现有用户的全新安装的理想解决方案，也可用于演示目的。
