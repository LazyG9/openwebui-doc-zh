---
sidebar_position: 400
title: "⭐ 功能特性"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的主要功能特性 ⭐

- 🚀 **轻松部署**：使用 Docker 或 Kubernetes（`kubectl`、`kustomize` 或 `helm`）无缝安装，支持带有捆绑 Ollama 的 `:ollama` 镜像和带有 CUDA 支持的 `:cuda` 镜像，提供无忧的使用体验。

- 🤝 **OpenAI API 集成**：轻松集成 OpenAI 兼容的 API，实现与 Ollama 模型并行的多样化对话。OpenAI API URL 可以自定义，以便与各种第三方应用程序链接。

- 🛡️ **精细的权限和用户组**：通过允许管理员创建详细的用户角色和权限，我们确保了安全的用户环境。这种精细度不仅增强了安全性，还允许定制用户体验，培养用户之间的所有权和责任感。

- 📱 **响应式设计**：在台式电脑、笔记本电脑和移动设备上享受无缝体验。

- 📱 **移动端渐进式 Web 应用**：在移动设备上享受原生渐进式 Web 应用体验，可在 `localhost` 或个人域名上离线访问，并提供流畅的用户界面。为了使我们的 PWA 可以安装在您的设备上，它必须在安全的环境中提供。这通常意味着它必须通过 HTTPS 提供服务。
  - 要设置 PWA，您需要了解 Linux、Docker 和反向代理（如 `Nginx`、`Caddy` 或 `Traefik`）等技术。使用这些工具可以帮助简化构建和部署适合您需求的 PWA 的过程。虽然没有"一键安装"选项，而且通过 HTTPS 安全部署 Open WebUI 实例需要用户经验，但使用这些资源可以让创建和部署适合您需求的 PWA 变得更容易。

- ✒️🔢 **完整的 Markdown 和 LaTeX 支持**：通过全面的 Markdown 和 LaTeX 功能提升您的大语言模型体验，实现更丰富的交互。

- 🧩 **模型构建器**：直接从 Open WebUI 轻松创建 Ollama 模型。创建和添加自定义角色和代理，自定义聊天元素，并通过 [Open WebUI Community](https://openwebui.com/) 集成轻松导入模型。

- 📚 **本地和远程 RAG 集成**：通过我们尖端的检索增强生成（RAG）技术，在聊天中探索您的文档，开启对话交互的未来。文档可以加载到工作区域，之后可以在查询前使用 `#` 符号访问，或者通过以 `#` 开始提示词，后跟 URL 来集成网页内容。

- 🔍 **RAG 网页搜索**：您可以使用各种搜索提供商进行网页搜索，并将结果直接注入到您的本地检索增强生成（RAG）体验中。

- 🌐 **网页浏览功能**：通过使用 `#` 命令后跟 URL，将网站无缝集成到您的聊天体验中。此功能使您能够将网页内容直接整合到对话中，从而增强交互的丰富性和深度。

- 🎨 **图像生成集成**：无缝整合图像生成功能，通过动态视觉内容丰富您的聊天体验。

- ⚙️ **并发模型使用**：轻松同时使用多个模型，利用它们的独特优势获得最佳响应。并行利用多样化的模型模态来增强您的体验。

- 🔐 **基于角色的访问控制（RBAC）**：通过受限权限确保安全访问。只有授权人员可以访问您的 Ollama，而模型创建和拉取权限仅限管理员使用。

- 🌐🌍 **多语言支持**：通过我们的国际化（`i18n`）支持，以您喜欢的语言体验 Open WebUI。我们邀请您加入我们，扩展我们支持的语言！我们正在积极寻找贡献者！

- 🌟 **持续更新**：我们致力于通过定期更新、修复和新功能来改进 Open WebUI。

## 以及更多令人瞩目的功能，包括... ⚡️

---

### 🔧 管道支持

- 🔧 **管道框架**：通过我们的模块化插件框架无缝集成和自定义您的 Open WebUI 体验，增强定制性和功能性 (https://github.com/open-webui/pipelines)。我们的框架允许轻松添加自定义逻辑和集成 Python 库，从 AI 代理到家庭自动化 API。

- 📥 **上传管道**：可以直接从 `管理面板` > `设置` > `管道` 菜单上传管道，简化管道管理流程。

#### 我们的管道框架可能性无限，几乎没有边界。从一些预构建的管道开始，帮助您入门！

- 🔗 **函数调用**：通过管道无缝集成 [函数调用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，通过高级函数调用功能增强您的大语言模型交互。

- 📚 **自定义 RAG**：无缝集成 [自定义检索增强生成（RAG）](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) 管道，通过自定义 RAG 逻辑增强您的大语言模型交互。

- 📊 **使用 Langfuse 监控消息**：通过 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 管道实时监控和分析消息交互使用统计。

- ⚖️ **用户速率限制**：通过控制发送到大语言模型的请求流量来高效管理 API 使用，使用 [速率限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) 管道防止超过速率限制。

- 🌍 **实时 LibreTranslate 翻译**：使用 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 管道将实时翻译集成到您的大语言模型交互中，实现跨语言通信。
  - 请注意，此管道需要在 Docker 容器中进一步设置 LibreTranslate 才能工作。

- 🛡️ **有害消息过滤**：我们的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 管道自动过滤有害消息，维护干净安全的聊天环境。

- 🔒 **LLM-Guard**：通过 [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 管道确保大语言模型交互的安全性，该管道具有提示词注入扫描器，可以检测和缓解针对大语言模型的巧妙输入操作。这可以保护您的大语言模型免受数据泄露，并增加对提示词注入攻击的抵抗层。

- 🕒 **对话轮次限制**：通过 [对话轮次限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) 管道设置对话轮次限制，改善交互管理。

- 📈 **OpenAI 生成统计**：我们的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 管道为 OpenAI 模型提供详细的生成统计信息。

- **🚀 多模型支持**：我们与来自[各种提供商](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers)的各种 AI 模型的无缝集成扩展了您的可能性，提供广泛的语言模型供您选择和交互。

#### 除了广泛的功能和自定义选项外，我们还提供[一个可直接使用的示例管道库](https://github.com/open-webui/pipelines/tree/main/examples)以及[一个实用的示例脚手架管道](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py)来帮助您入门。这些资源将简化您的开发过程，使您能够使用管道和 Python 快速创建强大的大语言模型交互。编码愉快！💡

---

### 🖥️ 用户体验

- 🖥️ **直观的界面**：聊天界面以用户为中心设计，借鉴了 ChatGPT 的用户界面。

- ⚡ **快速响应**：享受可靠的快速和响应性能。

- 🎨 **启动画面**：简单的加载启动画面，提供更流畅的用户体验。

- 📦 **Pip 安装方式**：可以通过命令 `pip install open-webui` 安装 Open WebUI，简化了安装过程，使新用户更容易上手。更多信息请访问：https://pypi.org/project/open-webui/。

- 🌈 **主题定制**：通过一系列选项个性化您的 Open WebUI 体验，包括各种简洁而优雅的主题、可自定义的聊天背景图片，以及三种模式选项：浅色、深色或 OLED 深色模式 - 或者让*她*为您选择！;)

- 💻 **代码语法高亮**：我们的语法高亮功能增强了代码可读性，提供清晰简洁的代码视图。

- ↕️ **双向聊天支持**：您可以轻松在从左到右和从右到左的聊天方向之间切换，以适应不同的语言偏好。

- 📱 **移动端可访问性**：在移动设备上可以通过简单的滑动手势打开和关闭侧边栏。

- 📂 **统一工作区**：统一的工作区部分在一个便捷的位置提供对所有模型文件、提示词、文档、工具和函数的访问，简化您的工作流程。

- 💾 **持久化设置**：受益于 Open WebUI 中保存和持久化的设置，存储在 config.json 文件中，便于访问和重用。

- ❓ **快速访问文档和快捷键**：位于主 UI 屏幕右下角的问号按钮（在台式电脑和笔记本电脑等较大屏幕上可用）为用户提供了对 Open WebUI 文档页面和可用键盘快捷键的快速访问。

- 📜 **更新日志和检查更新**：用户可以在 `设置` > `关于` > `查看新功能` 菜单中访问全面的更新日志和检查更新，该菜单提供最新功能、改进和错误修复的快速概览，以及检查更新的功能。

---

### 💬 对话功能

- 🔍 **RAG 嵌入支持**：直接在 `管理面板` > `设置` > `文档` 菜单中更改检索增强生成（RAG）嵌入模型，增强文档处理。此功能支持 Ollama 和 OpenAI 模型。

- 📜 **RAG 功能中的引用**：检索增强生成（RAG）功能允许用户轻松追踪提供给大语言模型的文档上下文，并添加参考点的引用。

- 🌟 **增强的 RAG 管道**：我们的 RAG 嵌入功能的可切换混合搜索子功能通过 `BM25` 增强了 RAG 功能，使用 `CrossEncoder` 进行重新排序，并具有可配置的相关性分数阈值。

- 📹 **YouTube RAG 管道**：专门用于通过视频 URL 总结 YouTube 视频的检索增强生成（RAG）管道可以直接与视频转录内容进行流畅交互。

- 🔄 **多模态支持**：轻松使用支持多模态交互的模型，包括图像（`例如，LLaVA`）。

- 🤖 **多模型支持**：快速在不同模型之间切换，实现多样化的聊天交互。

- 👥 **'@' 模型集成**：通过在对话过程中无缝切换到任何可访问的本地或外部模型，用户可以在单个聊天中利用多个模型的集体智能。这可以通过在聊天中使用 `@` 命令按名称指定模型来实现。

- 🏷️ **对话标签**：轻松对聊天进行分类和定位，便于快速参考和简化数据收集。

- 👶 **聊天克隆**：轻松克隆和保存任何聊天的快照，以供将来参考或继续。此功能使您可以轻松地从上次停止的地方继续，或与他人分享您的会话。要创建聊天副本，只需在聊天的下拉选项中点击 `克隆` 按钮。您能跟上您的克隆吗？

- 📜 **提示词预设支持**：使用聊天输入中的 `/` 命令即时访问自定义预设提示词。轻松加载预定义的对话开场白并加快您的交互。通过 [Open WebUI Community](https://openwebui.com/) 集成轻松导入提示词或创建您自己的提示词！

- 📅 **提示词变量支持**：可以在系统提示词中或通过使用斜杠命令在聊天中直接选择提示词来使用提示词变量，如 `{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}` 和 `{{USER_LOCATION}}`。
  - 请注意，`{{USER_LOCATION}}` 提示词变量需要通过 HTTPS 的安全连接才能工作。要使用此特定提示词变量，请确保从 `设置` > `界面` 菜单中启用了 `{{USER_LOCATION}}`。
  - 请注意，`{{CLIPBOARD}}` 提示词变量需要访问您设备的剪贴板。

- 🧠 **记忆功能**：通过 `设置` > `个性化` > `记忆` 菜单手动添加您希望大语言模型记住的信息。可以添加、编辑和删除记忆。

---

### 💻 模型管理

- 🛠️ **模型构建器**：所有模型都可以在模型工作区中使用持久化的模型构建器模式进行构建和编辑。

- 📚 **模型知识支持**：能够直接从模型工作区将函数和文档附加到模型，增强每个模型可用的信息。

- 🗂️ **模型预设**：为 Ollama 和 OpenAI API 创建和管理模型预设。

- 🏷️ **模型标签**：模型工作区使用户能够使用标签组织他们的模型。

- 📋 **模型选择器下拉排序**：可以通过在模型工作区中拖放到所需位置来轻松组织模型，这些更改将反映在模型下拉菜单中。

- 🔍 **模型选择器下拉菜单**：通过包含的搜索过滤器和带有模型标签和模型描述的详细模型信息，轻松找到和选择您的模型。

- ⚙️ **使用高级参数进行精细调整**：通过调整模型参数（如 `seed`、`temperature`、`frequency penalty`、`context length`、`seed` 等）获得更深层次的控制。

- 🔄 **无缝集成**：直接从 [Ollama 库](https://ollama.com/library/) 的模型页面复制任何 `ollama run {model:tag}` CLI 命令，并将其粘贴到模型下拉菜单中，轻松选择和拉取模型。

- 🗂️ **创建 Ollama 模型文件**：要为 Ollama 创建模型文件，请导航至 `管理面板` > `设置` > `模型` > `创建模型` 菜单。

- ⬆️ **GGUF 文件模型创建**：通过从 `管理设置` > `设置` > `模型` > `实验性` 菜单直接从 Open WebUI 上传 GGUF 文件，轻松创建 Ollama 模型。该过程已经简化，可以选择从您的机器上传或从 Hugging Face 下载 GGUF 文件。

- ⚙️ **默认模型设置**：新聊天的默认模型偏好可以在移动设备上通过 `设置` > `界面` 菜单设置，或者在台式电脑和笔记本电脑上更容易地在新聊天的模型选择器下拉菜单中设置。

- 💡 **大语言模型响应洞察**：可以查看每个生成响应的详细信息，包括外部模型 API 洞察和全面的本地模型信息。

- 📥🗑️ **下载/删除模型**：可以直接从 Open WebUI 轻松下载或删除模型。

- 🔄 **更新所有 Ollama 模型**：一个便捷的按钮允许用户在一次操作中更新所有本地安装的模型，简化模型管理。

- 🍻 **TavernAI 角色卡集成**：在我们的模型构建器中体验增强的视觉故事讲述，通过 TavernAI 角色卡集成。用户可以将 TavernAI 角色卡 PNG 直接无缝整合到他们的模型文件中，创造更身临其境和引人入胜的用户体验。

- 🎲 **模型游乐场（测试版）**：使用模型游乐场区域（`测试版`）试用模型，该区域使用户能够在沙盒环境中轻松测试和探索模型功能和参数，然后再部署到实时聊天环境中。

---

### 👥 协作功能

- 🗨️ **本地聊天共享**：以高效和无缝的方式在用户之间生成和共享聊天链接，从而增强协作和沟通。

- 👍👎 **RLHF 标注**：通过点赞或点踩对您的消息进行评分，然后可以选择提供文本反馈，便于创建用于人类反馈强化学习（`RLHF`）的数据集。利用您的消息来训练或微调模型，同时确保本地保存数据的机密性。

- 🤝 **社区共享**：通过点击 `分享到 Open WebUI 社区` 按钮，与 [Open WebUI Community](https://openwebui.com/) 分享您的聊天会话。此功能允许您与其他用户互动并在平台上协作。
  - 要使用此功能，请登录您的 Open WebUI Community 账户。分享您的聊天可以培养充满活力的社区，鼓励知识共享，并促进联合问题解决。请注意，聊天会话的社区共享是一个可选功能。只有管理员可以在 `管理设置` > `设置` > `常规` 菜单中开启或关闭此功能。

---

### 📚 历史和归档

- 📜 **聊天历史**：通过聊天导航侧边栏轻松访问和管理您的对话历史。在 `设置` > `聊天` 菜单中关闭聊天历史，以防止在新的交互中创建聊天历史。

- 🔄 **重新生成历史访问**：轻松重访和探索您的整个大语言模型响应重新生成历史。

- 📬 **归档聊天**：轻松存储您与模型进行的已完成对话，以供将来参考或交互，保持整洁和无杂乱的聊天界面。

- 🗃️ **归档所有聊天**：此功能允许您一次性快速归档所有聊天。

- 📦 **导出所有归档聊天为 JSON**：此功能使用户能够轻松地将所有归档的聊天导出为单个 JSON 文件，可用于备份或传输目的。

- 📄 **下载聊天为 JSON/PDF/TXT**：轻松以您喜欢的 `.json`、`.pdf` 或 `.txt` 格式单独下载您的聊天。

- 📤📥 **导入/导出聊天历史**：通过 `导入聊天` 和 `导出聊天` 选项无缝移动您的聊天数据进出平台。

- 🗑️ **删除所有聊天**：此选项允许您永久删除所有聊天，确保重新开始。

---

### 🎙 语音和无障碍

- 🗣️ **语音转文本**：通过语音输入功能，轻松地与您的模型进行对话。

- 🔊 **文本转语音**：通过文本转语音功能，让您的模型回应变得生动。

- 🌐 **多语言支持**：支持多种语言的语音输入和输出。

- 🎯 **语音命令**：使用语音命令来控制界面，实现免手操作。

- ⌨️ **键盘快捷键**：通过键盘快捷键提高工作效率。

- 🔍 **放大/缩小**：通过浏览器的缩放功能调整界面大小。

- 🌙 **深色模式**：为了减少眼睛疲劳，提供深色主题选项。

- 📱 **响应式设计**：在所有设备上都能提供最佳的用户体验。

---

### 🐍 代码执行

- 🔄 **代码解释器**：通过内置的代码解释器，直接在聊天界面中执行 Python 代码。

- 📊 **数据可视化**：使用 Python 库创建图表和可视化效果。

- 📝 **代码编辑**：在代码块中编辑和修改代码。

- 🔍 **语法高亮**：支持多种编程语言的语法高亮显示。

- 🚀 **实时执行**：立即查看代码执行结果。

- 📋 **代码片段**：保存和重用常用的代码片段。

- 🔒 **安全执行**：在安全的沙盒环境中运行代码。

- 📤 **导出结果**：将代码执行结果导出为多种格式。

---

### 🔒 集成和安全

- 🔐 **SSO 认证**：支持多种单点登录选项，包括 Google、Microsoft 和 OIDC。

- 🛡️ **角色访问控制**：通过基于角色的访问控制（RBAC）管理用户权限。

- 🔑 **API 密钥管理**：安全地管理和存储 API 密钥。

- 🌐 **代理支持**：支持通过代理服务器进行连接。

- 🔄 **Webhook 集成**：通过 Webhook 实现与其他系统的集成。

- 📊 **使用统计**：跟踪和监控系统使用情况。

- 🚫 **速率限制**：实施用户请求的速率限制。

- 🔍 **审计日志**：记录系统活动以供审计。

- 🛠️ **自定义集成**：支持与第三方系统的自定义集成。

- 🔒 **数据加密**：确保敏感数据的安全存储和传输。

---

### 👑 管理功能

- 👑 **超级管理员分配**：自动将第一个注册用户指定为超级管理员，其角色不可更改，即使是其他管理员也无法修改。

- 🛡️ **精细的用户权限**：通过可自定义的基于角色的权限限制用户操作和访问，确保只有授权人员才能执行特定任务。

- 👥 **多用户管理**：具有分页功能的直观管理面板，让您可以无缝管理多个用户，简化用户管理和生命周期管理。

- 🔧 **管理面板**：用户管理系统旨在简化用户的加入和管理，提供直接添加用户或通过 CSV 批量导入的选项。

- 👥 **活跃用户指示器**：监控活跃用户数量以及各用户正在使用的模型，帮助判断何时可能因用户数量过多而影响性能。

- 🔒 **默认注册角色**：为新注册用户指定默认角色为 `待定`、`用户` 或 `管理员`，灵活管理新用户的权限和访问级别。

- 🔒 **禁止新注册**：启用禁止新用户注册的选项，限制平台访问并维持固定用户数量。

- 🔒 **禁止删除聊天**：管理员可以切换设置，防止所有用户删除其聊天消息，确保所有聊天消息都保留以供审计或合规目的。

- 🔗 **Webhook 集成**：通过 webhook 订阅新用户注册事件（兼容 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams`），提供实时通知和自动化功能。

- 📣 **可配置通知横幅**：管理员可以在 config.json 中创建可自定义的持久横幅，具有内容、背景颜色（`info`、`warning`、`error` 或 `success`）和可关闭性等选项。横幅仅对已登录用户可见，确保敏感信息的机密性。

- 🛡️ **模型白名单**：通过允许管理员为具有 `用户` 角色的用户设置模型白名单来增强安全性和访问控制，确保只能访问授权模型。

- 🔑 **社区共享管理控制**：管理员可以通过 `管理面板` > `设置` 菜单中的开关为所有用户启用或禁用社区共享。此开关允许管理员管理可访问性和隐私，确保安全环境。管理员可以选择为所有用户启用或禁用 `分享到社区` 按钮，从而控制社区参与和协作。

- 📧 **可信邮箱认证**：可选择使用可信邮箱头进行认证，为您的 Open WebUI 实例添加额外的安全性和认证层。

- 🔒 **后端反向代理支持**：通过 Open WebUI 后端与 Ollama 的直接通信加强安全性。这一关键功能消除了在局域网（LAN）上暴露 Ollama 的需求。从 Open WebUI 发送到 `/ollama/api` 路由的请求会从后端无缝重定向到 Ollama，增强整体系统安全性并提供额外的保护层。

- 🔒 **认证**：请注意，Open WebUI 本身不支持联合认证方案，如 SSO、OAuth、SAML 或 OIDC。但是，它可以配置为将认证委托给认证反向代理，从而实现单点登录（`SSO`）体验。此设置允许您集中用户认证和管理，增强安全性和用户便利性。通过将 Open WebUI 与认证反向代理集成，您可以利用现有的认证系统并简化用户对 Open WebUI 的访问。有关配置此功能的更多信息，请参阅[联合认证支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可选认证**：通过将 `WEBUI_AUTH` 设置为 `False` 来享受禁用认证的灵活性。这是没有现有用户的全新安装的理想解决方案，也可用于演示目的。

---
