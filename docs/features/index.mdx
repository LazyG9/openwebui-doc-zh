---
sidebar_position: 400
title: "⭐ 功能"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的关键功能 ⭐

- 🚀 **轻松设置**：通过 Docker、Kubernetes、Podman、Helm Charts（`kubectl`、`kustomize`、`podman` 或 `helm`）无缝安装，支持 `:ollama` 镜像与捆绑的 Ollama 以及 `:cuda` 的 CUDA 支持，提供无忧体验。

- 🛠️ **引导式初始设置**：清晰完成设置过程，包括在首次设置时明确创建管理员账户的指示。

- 🤝 **OpenAI API 集成**：轻松集成 OpenAI API，以便与 Ollama 模型进行多样化对话。OpenAI API URL 可以自定义，以便与各种第三方应用程序无缝集成 Open WebUI。

- 🛡️ **细粒度权限和用户组**：通过允许管理员在工作区内创建详细的用户角色、用户组和权限，我们为所有用户提供了一个安全的用户环境。这种细粒度不仅增强了安全性，还允许定制用户体验，培养用户的归属感和责任感。

- 📱 **响应式设计**：在台式电脑、笔记本电脑和移动设备上享受无缝体验。

- 📱 **移动端渐进式 Web 应用**：在移动设备上享受本地渐进式 Web 应用体验，支持 `localhost` 或个人域名的离线访问，并提供流畅的用户界面。为了使我们的 PWA 可安装在您的设备上，它必须在安全的环境中交付。这通常意味着它必须通过 HTTPS 提供服务。

  :::info

  - 要设置 PWA，您需要了解一些技术，如 Linux、Docker 和反向代理（如 `Nginx`、`Caddy` 或 `Traefik`）。使用这些工具可以帮助简化构建和部署符合您需求的 PWA 的过程。虽然没有可用的"一键安装"选项，并且安全部署您的 Open WebUI 实例到 HTTPS 需要用户经验，但使用这些资源可以更轻松地创建和部署符合您需求的 PWA。

  :::

- ✒️🔢 **完整的 Markdown 和 LaTeX 支持**：通过全面的 Markdown、LaTeX 和富文本功能提升您的 LLM 体验，实现丰富的互动。

- 🧩 **模型构建器**：直接从 Open WebUI 轻松创建基于 Ollama 模型的自定义模型。通过 [Open WebUI 社区](https://openwebui.com/) 集成，创建和添加自定义角色和智能体，自定义模型元素，并轻松导入模型。

- 📚 **本地和远程 RAG 集成**：通过我们尖端的检索增强生成（RAG）技术，在聊天中探索文档，进入聊天互动的未来。文档可以加载到工作区的 `Documents` 选项卡中，然后可以在查询前使用井号键 [`#`] 访问，或通过井号键 [`#`] 开始提示，后跟 URL 以进行网页内容集成。

- 🔍 **RAG 的网页搜索**：您可以使用各种搜索提供商进行网页搜索，并将结果直接注入到本地检索增强生成（RAG）体验中。

- 🌐 **网页浏览功能**：通过使用 `#` 命令后跟 URL，将网站无缝集成到您的聊天体验中。此功能使得可以将网页内容直接纳入您的对话中，从而增强互动的丰富性和深度。

- 🎨 **图像生成集成**：无缝集成图像生成功能，以动态视觉内容丰富您的聊天体验。

- ⚙️ **并发模型利用**：同时轻松使用多个模型，利用它们的独特优势以获得最佳响应。并行利用多种模型模态以增强您的体验。

- 🔐 **基于角色的访问控制 (RBAC)**：通过限制权限确保安全访问。只有授权人员才能访问您的 Ollama，而模型创建和拉取权限仅限于管理员。

- 🌐🌍 **多语言支持**：通过我们的国际化（`i18n`）支持，以您偏好的语言体验 Open WebUI。我们邀请您加入我们，扩展我们支持的语言！我们正在积极寻找贡献者！

- 🌟 **持续更新**：我们致力于通过定期更新、修复和新功能来改进 Open WebUI。

## 以及许多其他显著功能，包括... ⚡️

---

### 🔧 管道支持

- 🔧 **管道框架**：通过我们的模块化插件框架无缝集成和自定义您的 Open WebUI 体验，以增强自定义和功能（https://github.com/open-webui/pipelines）。我们的框架允许轻松添加自定义逻辑和集成 Python 库，从 AI 智能体到家庭自动化 API。

- 📥 **上传管道**：可以直接从 `Admin Panel` > `Settings` > `Pipelines` 菜单上传管道，简化管道管理过程。

#### 我们的管道框架的可能性无穷无尽，几乎没有限制。可以从一些预构建的管道开始，帮助您入门！

- 🔗 **函数调用**：通过管道无缝集成[函数调用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，以增强您的 LLM 交互，提供高级函数调用功能。

- 📚 **自定义 RAG**：无缝集成[自定义检索增强生成（RAG）](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag)管道，以增强您的 LLM 交互，提供自定义 RAG 逻辑。

- 📊 **使用 Langfuse 进行消息监控**：通过 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 管道实时监控和分析消息交互的使用统计。

- ⚖️ **用户速率限制**：通过 [Rate Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) 管道有效管理 API 使用，控制发送到 LLM 的请求流量，以防止超出速率限制。

- 🌍 **实时 LibreTranslate 翻译**：使用 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 管道将实时翻译集成到您的 LLM 交互中，实现跨语言交流。
  - 请注意，此管道需要在 Docker 容器中进一步设置 LibreTranslate 才能工作。

- 🛡️ **有害消息过滤**：我们的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 管道自动过滤有害消息，以保持清洁和安全的聊天环境。

- 🔒 **LLM-Guard**：通过 [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 管道确保 LLM 交互的安全，具有提示注入扫描器，可检测并减轻针对大型语言模型的巧妙输入操作。这保护您的 LLM 免受数据泄露，并增加了一层抵御提示注入攻击的防护。

- 🕒 **对话轮次限制**：通过 [Conversation Turn Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) 管道设置对话轮次限制，以改善交互管理。

- 📈 **OpenAI 生成统计**：我们的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 管道提供 OpenAI 模型的详细生成统计。

- **🚀 多模型支持**：我们与来自[各种提供商](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers)的各种 AI 模型无缝集成，扩展了您的可能性，提供广泛的语言模型供选择和互动。

#### 除了广泛的功能和自定义选项外，我们还提供[一系列可用的示例管道库](https://github.com/open-webui/pipelines/tree/main/examples)以及[一个实用的示例脚手架管道](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py)来帮助您入门。这些资源将简化您的开发过程，使您能够快速使用管道和 Python 创建强大的 LLM 交互。编码愉快！💡

---

### 🖥️ 用户体验

- 🖥️ **直观界面**：聊天界面以用户为中心设计，灵感来自 ChatGPT 的用户界面。

- ⚡ **快速响应**：享受可靠的快速响应性能。

- 🎨 **启动画面**：简单的加载启动画面，提供更流畅的用户体验。

- 🌐 **个性化界面**：从设置 > 界面中选择新设计的搜索登陆页面和经典聊天 UI，提供量身定制的体验。

- 📦 **Pip 安装方法**：可以通过命令 `pip install open-webui` 安装 Open WebUI，这简化了流程，使新用户更容易访问。有关更多信息，请访问：https://pypi.org/project/open-webui/。

- 🌈 **主题自定义**：通过一系列选项个性化您的 Open WebUI 体验，包括多种坚固而时尚的主题、可自定义的聊天背景图像和三种模式选项：浅色、深色或 OLED 深色模式——或者让*她*为您选择！;)

- 🖼️ **自定义背景支持**：从设置 > 界面中设置自定义背景，以个性化您的体验。

- 📝 **支持 Markdown 的丰富横幅**：在横幅中创建视觉吸引力的公告，支持 Markdown，提供更丰富和动态的内容。

- 💻 **代码语法高亮**：我们的语法高亮功能增强了代码的可读性，提供清晰简洁的代码视图。

- 🗨️ **用户消息中的 Markdown 渲染**：用户消息现在以 Markdown 渲染，增强了可读性和互动性。

- 🎨 **灵活的文本输入选项**：在聊天中切换富文本输入和传统文本区域输入，满足用户偏好，提供高级格式和简单文本输入之间的选择。

- 👆 **轻松的代码共享**：通过便捷的代码复制选项简化共享和协作过程，包括代码块中的浮动复制按钮和代码段的点击复制功能，节省时间并减少挫折。

- 🎨 **交互式工件**：直接在界面中渲染网页内容和 SVG，支持快速迭代和实时更改，以增强创造力和生产力。

- 🖊️ **实时代码编辑**：增强的代码块允许在 LLM 响应中直接进行实时编辑，支持工件的实时重载，简化编码和测试。

- 🔍 **增强的 SVG 交互**：SVG 图像（包括 Mermaid 图表）的平移和缩放功能，支持更深入的探索和对复杂概念的理解。

- 🔍 **文本选择快速操作**：在 LLM 响应中突出显示文本时出现浮动按钮，提供更深入的交互，如"提问"或"解释"，增强整体用户体验。

- ↕️ **双向聊天支持**：您可以轻松切换左右聊天方向，以适应各种语言偏好。

- 📱 **移动设备可访问性**：侧边栏可以通过简单的滑动手势在移动设备上打开和关闭。

- 🤳 **支持设备上的触觉反馈**：Android 设备支持触觉反馈，在某些交互过程中提供沉浸式触觉体验。

- 🔍 **用户设置搜索**：快速搜索设置字段，提高易用性和导航性。

- 📜 **离线 Swagger 文档**：离线访问对开发者友好的 Swagger API 文档，确保在任何地方都能完全访问。

- 💾 **性能优化**：延迟加载大型依赖项，最大限度地减少初始内存使用，提升性能并减少加载时间。

- 🚀 **持久且可扩展的配置**：Open WebUI 配置存储在数据库（webui.db）中，允许无缝负载平衡、高可用性设置和跨多个实例的持久设置，使访问和重用配置变得容易。

- 🔄 **便携的导入/导出**：轻松导入和导出 Open WebUI 配置，简化跨多个系统复制设置的过程。

- ❓ **快速访问文档和快捷键**：主 UI 屏幕右下角的问号按钮（在台式电脑和笔记本电脑等较大屏幕上可用）为用户提供了轻松访问 Open WebUI 文档页面和可用键盘快捷键的途径。

- 📜 **更新日志和检查更新**：用户可以在 `Settings` > `About` > `See What's New` 菜单中访问全面的更新日志和检查更新，快速概览最新功能、改进和错误修复，以及检查更新的能力。

---

### 💬 对话

- 💬 **真正的异步聊天**：享受不间断的多任务处理，支持真正的异步聊天，允许您创建聊天、离开并随时返回，响应已准备就绪。

- 🔔 **聊天完成通知**：当聊天在非活动选项卡中完成时，通过即时的 UI 内通知保持更新，确保您不会错过已完成的响应。

- 🌐 **通知 Webhook 集成**：即使在选项卡关闭时，也能通过可配置的 Webhook 通知接收长时间运行的聊天或外部集成需求的及时更新。

- 📚 **频道（测试版）**：通过 Discord/Slack 风格的聊天室探索用户与 AI 之间的实时协作，构建频道机器人，并为主动多智能体工作流解锁异步通信。

- 🖊️ **频道中的打字指示器**：通过频道中的实时打字指示器增强协作，让每个人都参与并知情。

- 👤 **用户状态指示器**：通过单击频道中的用户头像快速查看用户状态，提供更好的协调和可用性洞察。

- 💬 **聊天控制**：轻松调整每个聊天会话的参数，提供更精确的交互控制。

- 💖 **收藏响应管理**：直接从聊天概览中轻松标记和组织收藏的响应，增强检索和访问首选响应的便利性。

- 📌 **固定聊天**：支持固定聊天，允许您轻松访问重要对话。

- 🔍 **RAG 嵌入支持**：直接在 `Admin Panel` > `Settings` > `Documents` 菜单中更改检索增强生成（RAG）嵌入模型，增强文档处理。此功能支持 Ollama 和 OpenAI 模型。

- 📜 **RAG 功能中的引用**：检索增强生成（RAG）功能允许用户轻松跟踪输入到 LLM 的文档的上下文，并添加引用以供参考。

- 🌟 **增强的 RAG 管道**：通过 `BM25` 增强 RAG 功能，由 `CrossEncoder` 提供支持，并可配置相关性分数阈值的可切换混合搜索子功能。

- 📹 **YouTube RAG 管道**：通过视频 URL 直接总结 YouTube 视频的专用检索增强生成（RAG）管道，实现与视频字幕的流畅交互。

- 📁 **全面的文档检索**：在完全文档检索和传统片段之间切换，以实现摘要和增强文档功能。

- 🌟 **RAG 引用相关性**：轻松评估引用相关性，在 RAG 结果中添加相关百分比。

- 🗂️ **高级 RAG**：通过智能预处理聊天历史以确定最佳查询，提高 RAG 准确性。

- 📚 **RAG 内联引用**：从检索增强生成（RAG）响应中受益，改善跟踪并提供新上传文件的来源清晰度。

- 📁 **大文本处理**：可选地将大粘贴文本转换为文件上传，直接用于 RAG，保持聊天界面更干净。

- 🔄 **多模态支持**：轻松与支持多模态交互的模型互动，包括图像（例如，LLaVA）。

- 🤖 **多模型支持**：快速切换不同模型，进行多样化的聊天互动。

- 🔀 **多模型聊天中的响应合并**：通过将多个模型的响应合并为一个连贯的回复来增强对话。

- ✅ **同一模型在聊天中的多个实例**：增强多模型聊天以支持添加同一模型的多个实例。

- 💬 **临时聊天功能**：引入临时聊天功能，取代旧的聊天历史设置，以增强用户交互灵活性。

- 🖋️ **用户消息编辑**：增强用户聊天编辑功能，允许保存更改而不发送。

- 💬 **高效对话编辑**：使用 Cmd/Ctrl+Shift+Enter 快捷键快速直观地创建新消息对，简化对话长度测试。

- 🖼️ **客户端图像压缩**：保存带宽并提高性能，使用客户端图像压缩，允许您在设置 > 界面中压缩图像。

- 👥 **'@' 模型集成**：通过在对话中无缝切换到任何可访问的本地或外部模型，用户可以利用多个模型的集体智能进行单次聊天。这可以通过使用 `@` 命令在聊天中指定模型来完成。

- 🏷️ **对话标记**：轻松分类和定位标记聊天，快速参考和简化数据收集，使用我们高效的 'tag:' 查询系统，允许您管理、搜索和组织对话，而不会使界面混乱。

- 🎲 **自动标记**：对话可以可选地自动标记以提高组织效率，复制自动生成标题的效率。

- 🎲 **聊天克隆**：轻松克隆并保存任何聊天的快照，以供将来参考或继续。此功能使您可以轻松恢复或与他人分享您的会话。要创建聊天副本，只需单击聊天下拉选项中的 `Clone` 按钮。你能跟上你的克隆吗？

- ⭐ **可视化对话流程**：交互消息图表，以提高对话流程的可视化，增强复杂讨论的理解和导航。

- 📁 **聊天文件夹**：将聊天组织到文件夹中，拖放它们进行轻松管理，并轻松导出它们以供共享或分析。

- 📤 **轻松聊天导入**：通过简单拖放聊天导出（JSON）到侧边栏，将聊天导入到您的工作区。

- 📜 **提示预设支持**：通过聊天输入中的 `/` 命令立即访问自定义提示预设。轻松加载预定义的聊天启动器并加速交互。通过 [Open WebUI Community](https://openwebui.com/) 集成或创建您自己的导入提示！

- 📅 **提示变量支持**：提示变量，如 `{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}` 和 `{{USER_LOCATION}}` 可以在系统提示中使用或通过使用斜杠命令直接在聊天中选择提示。
  - 请注意，`{{USER_LOCATION}}` 提示变量需要通过 HTTPS 的安全连接。要利用这个特定的提示变量，请确保从 `Settings` > `Interface` 菜单中将 `{{USER_LOCATION}}` 切换为开。
  - 请注意，`{{CLIPBOARD}}` 提示变量需要访问您的设备剪贴板。

- 🧠 **记忆功能**：通过 `Settings` > `Personalization` > `Memory` 菜单手动添加您希望您的 LLM 记住的信息。记忆可以添加、编辑和删除。

---

### 💻 Model Management


- 🛠️ **Model Builder**：所有模型都可以通过模型编辑页面中的持久模型构建器进行构建和编辑。

- 📚 **模型知识支持**：可以直接从模型编辑页面附加工具、函数和知识集合到模型中，增强每个模型的可用信息。

- 🗂️ **模型预设**：为 Ollama 和 OpenAI API 创建和管理模型预设。

- 🏷️ **模型标记**：模型工作区允许用户使用标记组织他们的模型。

- 🔄 **模型选择器下拉排序**：可以通过将模型拖放到模型工作区中的所需位置来轻松组织模型，然后反映在模型下拉菜单中。

- 🔄 **模型选择器下拉**：通过模糊搜索和详细的模型信息使用模型标记和模型描述轻松找到和选择您的模型。

- ⌨️ **箭头键模型选择**：使用箭头键进行快速模型选择，增强可访问性。

- 🔧 **模型工作区中的快速操作**：增强 Shift 键快速操作以隐藏/显示和删除模型。

- 😄 **透明模型使用**：通过知识增强模型在查询时保持系统状态，感谢可见状态显示。

- ⚙️ **高级参数的精细调整**：通过调整模型参数（如 `seed`、`temperature`、`frequency penalty`、`context length`、`seed` 等）获得更深入的控制。

- 🔄 **无缝集成**：直接从 [Ollama 库](https://ollama.com/library/) 复制任何 `ollama run {model:tag}` CLI 命令，并将其粘贴到模型下拉菜单中，轻松选择和拉取模型。

- 🗂️ **创建 Ollama Modelfile**：要为 Ollama 创建模型文件，请导航到 `Admin Panel` > `Settings` > `Models` > `Create a model` 菜单。

- ⬆️ **GGUF 文件模型创建**：通过从 Open WebUI 直接上传 GGUF 文件，从 `Admin Settings` > `Settings` > `Model` > `Experimental` 菜单中轻松创建 Ollama 模型。该过程已通过选项得到简化，可以选择从您的机器上传或从 Hugging Face 下载 GGUF 文件。

- ⚙️ **默认模型设置**：新聊天的默认模型偏好可以在移动设备上的 `Settings` > `Interface` 菜单中设置，或者可以在桌面 PC 和笔记本电脑上的模型选择器下拉菜单中更轻松地设置。

- 💡 **LLM 响应洞察**：可以查看每个生成的响应，包括外部模型 API 洞察和全面的本地模型信息。

- 🕒 **模型概览**：查看关键模型详细信息，包括模型哈希和最后修改时间戳，直接在模型工作区中进行增强跟踪和管理。

- 📥🗑️ **下载/删除模型**：可以直接从 Open WebUI 中下载或删除模型。

- 🔄 **更新所有 Ollama 模型**：方便的按钮允许用户在一次操作中更新所有本地安装的模型，简化模型管理。

- 🍻 **TavernAI Character Card Integration**：在模型构建器中体验增强的视觉讲故事与 TavernAI Character Card Integration。用户可以无缝地将 TavernAI 角色卡片 PNG 直接集成到他们的模型文件中，创建更身临其境和参与的用户体验。

- 🎲 **模型游乐场（测试版）**：通过模型游乐场区域（`beta`）尝试模型，用户可以在部署到实时聊天环境之前，在沙盒环境中轻松测试和探索模型功能和参数。

---

### 👥 Collaboration

- 🗨️ **本地聊天共享**：通过高效且无缝的方式在用户之间生成和共享聊天链接，从而增强协作和沟通。

- 👍👎 **RLHF 注释**：通过使用拇指向上或拇指向下 AMD 提供响应的评分，增强消息的影响力，并提供文本反馈选项，以促进从人类反馈强化学习（RLHF）的数据集创建。利用您的消息来训练或微调模型，同时确保本地保存的数据的机密性。

- 🔧 **全面的反馈导出**：将反馈历史数据导出为 JSON，以无缝集成 RLHF 处理和进一步分析，提供改进的宝贵见解。

- 🤝 **社区共享**：通过点击 `Share to Open WebUI Community` 按钮，与 [Open WebUI Community](https://openwebui.com/) 共享您的聊天会话。此功能允许您与平台上的其他用户协作。
  - 要利用此功能，请登录您的 Open WebUI Community 帐户。共享聊天会促进充满活力的社区，鼓励知识共享，并促进联合问题解决。请注意，聊天会话的社区共享是一个可选功能。只有管理员可以在 `Admin Settings` > `Settings` > `General` 菜单中切换此功能。

- 🏆 **社区排行榜**：通过我们的排行榜系统与我们排行榜系统竞争和跟踪您的性能，该系统利用 ELO 评分系统，并允许选择性共享反馈历史。

- ⚔️ **模型评估竞技场**：直接从 Admin Settings 进行模型 A/B 测试，以进行真正的侧边对边比较，使找到适合您需求的更好模型变得更加容易。

- 🎯 **基于主题的排名**：通过我们的实验性基于主题的重排序系统发现更准确的排名，该系统根据反馈中的标签相似性调整排行榜。

- 📂 统一且协作的工作区：访问和管理所有模型文件、提示、文档、工具和功能，同时还可以让多个用户协作和贡献模型、知识、提示或工具，简化工作流程并增强团队合作。

---

### 📚 History & Archive

- 📌 **聊天历史**：通过聊天导航侧边栏轻松访问和管理您的聊天历史。在 `Settings` > `Chats` 菜单中关闭聊天历史以防止创建新的交互。

- 🔄 **重生成历史访问**：轻松重访并探索整个 LLM 响应重生成历史。

- 📬 **存档聊天**：轻松存储已完成与模型对话的完成，保持整洁且无杂乱的聊天界面。

- 🗃️ **存档所有聊天**：此功能允许您一次快速存档所有聊天。

- 📦 **导出所有存档聊天为 JSON**：此功能允许用户轻松导出所有存档聊天，以单个 JSON 文件形式，可用于备份或传输。

- 📄 **下载聊天为 JSON/PDF/TXT**：轻松下载您首选格式的聊天，以 `.json`、`.pdf` 或 `.txt` 格式。

- 📤📥 **导入/导出聊天历史**：通过 `Import Chats` 和 `Export Chats` 选项，轻松将聊天数据在平台之间移动。

- 🗑️ **删除所有聊天**：此选项允许您永久删除所有聊天，确保全新开始。

---


### 🎙️ 音频、语音与无障碍

- 🗣️ **语音输入支持**：通过语音交互与您的模型互动；享受直接与模型对话的便利。此外，探索在静音3秒后自动发送语音输入的选项，以简化体验。
  - 需要手动通过 HTTPS 设置安全连接才能使用麦克风访问，或[自行承担风险手动将您的 URL 列入白名单](https://docs.openwebui.com/troubleshooting/microphone-error)。

- 😊 **表情符号通话**：从 `Settings` > `Interface` 菜单中切换此功能，允许 LLM 在语音通话中使用表情符号表达情感，以实现更动态的互动。
  - 该功能需要通过 HTTPS 的安全连接才能使用麦克风访问。

- 🎙️ **免提语音通话功能**：无需使用双手即可发起语音通话，使互动更加无缝。
  - 该功能需要通过 HTTPS 的安全连接才能使用麦克风访问。

- 📹 **视频通话功能**：启用与 LlaVA 和 GPT-4o 等支持视觉模型的视频通话，为您的通信增添视觉维度。
  - 该功能需要通过 HTTPS 的安全连接才能使用摄像头和麦克风访问。

- 👆 **点击中断**：在移动设备上通过简单的点击停止 AI 在语音对话中的讲话，确保对互动的无缝控制。

- 🎙️ **语音中断**：在移动设备上通过语音停止 AI 在语音对话中的讲话，确保对互动的无缝控制。

- 🔊 **可配置的文本转语音端点**：通过可配置的 OpenAI 兼容端点自定义您的文本转语音体验，以朗读 LLM 响应。

- 🔗 **直接呼叫模式访问**：直接从 URL 激活呼叫模式，为移动设备用户提供便捷的快捷方式。

- ✨ **可定制的文本转语音**：控制消息内容如何分段以进行文本转语音（TTS）生成请求，允许灵活的语音输出选项。

- 🔊 **Azure 语音服务集成**：支持 Azure 语音服务的文本转语音（TTS），为用户提供更广泛的语音合成选项。

- 🎚️ **可定制的音频播放**：允许用户在呼叫模式设置中根据自己的喜好调整音频播放速度，增强可访问性和可用性。

- 🎵 **广泛的音频兼容性**：支持多种音频文件格式的转录，包括 'audio/x-m4a'，以扩大平台内音频内容的兼容性。

- 🔊 **音频压缩**：实验性的音频压缩允许绕过 OpenAI 的语音转文本处理的 25MB 限制，扩展基于音频的交互可能性。

- 🗣️ **实验性 SpeechT5 TTS**：享受本地 SpeechT5 支持，以改善文本转语音功能。

---

### 🐍 代码执行

- 🚀 **多功能、与 UI 无关、兼容 OpenAI 的插件框架**：无缝集成和自定义 [Open WebUI Pipelines](https://github.com/open-webui/pipelines)，以实现高效的数据处理和模型训练，确保最终的灵活性和可扩展性。

- 🛠️ **原生 Python 函数调用**：在 Open WebUI 中直接使用原生函数调用访问 Python 的强大功能。通过内置代码编辑器轻松集成自定义代码，以构建独特的功能，如自定义 RAG 管道、网页搜索工具，甚至是类似智能体的操作，并在 `Tools` 和 `Functions` 工作区中无缝开发和集成功能代码。

- 🐍 **Python 代码执行**：通过 Pyodide 在浏览器中本地执行 Python 代码，支持 Pyodide 的一系列库。

- 🌊 **Mermaid 渲染**：使用 [Mermaid 图表和绘图工具](https://mermaid.js.org/intro/)直接在 Open WebUI 中创建视觉上吸引人的图表和流程图，支持 Mermaid 语法渲染。

- 🔗 **Iframe 支持**：通过使用函数和工具直接在您的聊天界面中渲染 HTML。

---

### 🔒 集成与安全

- ✨ **多种 OpenAI 兼容 API 支持**：无缝集成和自定义各种 OpenAI 兼容的 API，增强您的聊天互动的多样性。

- 🔑 **简化的 API 密钥管理**：轻松生成和管理密钥，以利用 Open WebUI 与 OpenAI 库，简化集成和开发。

- 🌐 **HTTP/S 代理支持**：通过 `http_proxy` 或 `https_proxy` 环境变量轻松配置网络设置。这些变量如果设置，应包含 HTTP 和 HTTPS 代理的 URL。

- 🌐🔗 **外部 Ollama 服务器连接**：通过配置环境变量，无缝链接到托管在不同地址的外部 Ollama 服务器。

- 🛢️ **灵活的数据库集成**：通过环境变量无缝连接到自定义数据库，包括 SQLite、Postgres 和多个向量数据库如 Milvus，实现灵活和可扩展的数据管理。

- 🌐🗣️ **外部语音转文本支持**：添加外部语音转文本（`STT`）服务提供了增强的灵活性，允许用户选择他们首选的提供商以实现无缝交互。

- 🌐 **远程 ChromaDB 支持**：通过连接到远程 ChromaDB 服务器扩展您的数据库功能。

- 🔀 **多 Ollama 实例负载均衡**：轻松分配聊天请求到多个 Ollama 实例，以增强性能和可靠性。

- 🚀 **高级负载均衡和可靠性**：利用增强的负载均衡能力、具有完整 Redis 支持的无状态实例和自动 WebSocket 重新连接，以提升 WebUI 的性能、可靠性和可扩展性，确保跨多个实例的无缝和不间断的交互。

- ☁️ **实验性 S3 支持**：启用具有 S3 支持的无状态 WebUI 实例，以增强可扩展性和平衡繁重的工作负载。

- 🛠️ **用户组的 OAuth 管理**：通过 OAuth 集成在协作环境中增强控制和可扩展性，实现组级管理。

---

### 👑 管理

- 👑 **超级管理员分配**：自动将首次注册的用户分配为超级管理员，具有不可更改的角色，其他管理员也无法修改。

- 🛡️ **细粒度用户权限**：通过可自定义的基于角色的权限限制用户操作和访问，确保只有授权人员可以执行特定任务。

- 👥 **多用户管理**：直观的管理面板带有分页功能，允许您无缝管理多个用户，简化用户管理和用户生命周期管理。

- 🔧 **管理面板**：用户管理系统旨在简化用户的入职和管理，提供直接添加用户或通过 CSV 批量导入的选项。

- 👥 **活跃用户指示器**：监控活跃用户数量以及谁在使用哪些模型，以帮助评估何时由于用户数量过多而可能影响性能。

- 🔒 **默认注册角色**：为新注册用户指定默认角色为 `pending`、`user` 或 `admin`，提供灵活性以管理新用户的权限和访问级别。

- 🔒 **防止新用户注册**：启用选项以禁用新用户注册，限制对平台的访问并保持固定的用户数量。

- 🔒 **防止聊天删除**：管理员可以切换设置以防止所有用户删除他们的聊天消息，确保所有聊天消息都保留以供审计或合规目的。

- 🔗 **Webhook 集成**：通过 webhook 订阅新用户注册事件（兼容 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams`），提供实时通知和自动化功能。

- 📣 **可配置的通知横幅**：管理员可以在 config.json 中创建可自定义的横幅，具有内容、背景颜色（`info`、`warning`、`error` 或 `success`）和可解散性选项。横幅仅对登录用户可见，确保敏感信息的机密性。

- 🛡️ **模型白名单**：通过允许管理员为具有 `user` 角色的用户白名单模型，增强安全性和访问控制，确保只有授权的模型可以被访问。

- 🔑 **社区共享的管理员控制**：管理员可以通过 `Admin Panel` > `Settings` 菜单中的切换为所有用户启用或禁用社区共享。此切换允许管理员管理可访问性和隐私，确保安全的环境。管理员可以选择为所有用户启用或禁用 `Share on Community` 按钮，这允许他们控制社区参与和协作。

- 📧 **可信电子邮件认证**：可选地使用可信电子邮件头进行认证，为保护您的 Open WebUI 实例添加额外的安全层和认证。

- 🔒 **后端反向代理支持**：通过 Open WebUI 的后端与 Ollama 之间的直接通信加强安全性。此关键功能消除了在局域网（LAN）上公开 Ollama 的需要。从 Open WebUI 发出的对 `/ollama/api` 路由的请求被无缝重定向到 Ollama，从而增强整体系统安全性并提供额外的保护层。

- 🔒 **认证**：请注意，Open WebUI 本身不支持联合认证方案，如 SSO、OAuth、SAML 或 OIDC。然而，它可以配置为将认证委托给认证反向代理，从而有效实现单点登录（`SSO`）体验。此设置允许您集中用户认证和管理，增强安全性和用户便利性。通过将 Open WebUI 与认证反向代理集成，您可以利用现有的认证系统并简化用户对 Open WebUI 的访问。有关配置此功能的更多信息，请参阅 [联合认证支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可选认证**：通过将 `WEBUI_AUTH` 设置为 `False`，享受禁用认证的灵活性。这是没有现有用户的新安装的理想解决方案，或可用于演示目的。

- 🚫 **高级 API 安全性**：基于自定义模型过滤器阻止 API 用户，增强安全性和对 API 访问的控制。

- ❗ **管理员更新**：确保管理员在登录时通过即时更新通知保持知情，随时了解最新的更改和系统状态。

- 👥 **用户组管理**：创建和管理用户组以实现无缝的组织和控制。

- 🔐 **基于组的访问控制**：根据用户组设置对模型、知识、提示和工具的细粒度访问，允许更受控和安全的环境。

- 🛠️ **细粒度用户权限**：轻松管理工作区权限，包括文件上传、删除、编辑和临时聊天，以及模型、知识、提示和工具的创建。

- 🔑 **LDAP 认证**：通过 LDAP 支持用户管理，增强安全性和可扩展性。

- 🌐 **可自定义的 OpenAI 连接**：享受自定义 OpenAI 设置的流畅操作，包括前缀 ID 支持和 API 的显式模型 ID 支持。

- 🔐 **Ollama API 密钥管理**：管理 Ollama 凭据，包括前缀 ID 支持，以实现安全和高效的操作。

- 🔄 **连接管理**：根据需要轻松启用或禁用单个 OpenAI 和 Ollama 连接。

- 🎨 **直观的模型工作区**：通过重新设计的用户友好界面管理用户和组的模型。

- 🔑 **API 密钥认证**：通过轻松启用或禁用 API 密钥认证来加强安全性。

- 🔄 **统一模型重置**：通过一键选项从管理设置中重置和删除所有模型。

- 🔓 **灵活的模型访问控制**：在不需要时，使用 'BYPASS_MODEL_ACCESS_CONTROL' 环境变量轻松绕过用户角色的模型访问控制，简化受信环境中的工作流程。

- 🔒 **可配置的 API 密钥认证限制**：灵活配置 API 密钥认证的端点限制，默认关闭以便在受信环境中更顺利地设置。

---
