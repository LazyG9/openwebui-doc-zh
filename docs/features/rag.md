---
sidebar_position: 11
title: "🔎 检索增强生成（RAG）"
---

检索增强生成（Retrieval Augmented Generation，简称 RAG）是一项前沿技术，通过整合多源上下文信息来增强 AI 模型的对话能力。它可以从本地文档、远程文件、网页内容，甚至 YouTube 视频等多媒体源中检索相关信息。系统会将检索到的文本与预定义的 RAG 模板结合，添加到用户的提示词之前，从而提供更准确、更符合上下文的回答。

RAG 的核心优势在于其强大的信息整合能力，这使其成为处理复杂对话场景的理想解决方案。例如，当用户询问特定文档或网页相关的问题时，RAG 可以智能地检索并整合相关信息到回答中。对于多媒体内容，如 YouTube 视频，RAG 可以分析视频字幕或说明文字，提取关键信息并融入对话中。

## 本地和远程文档集成

使用本地文档前，需要先完成以下步骤：
1. 通过工作区的"文档"部分上传文件
2. 在对话中使用 `#` 符号访问文档
3. 点击聊天框上方显示的格式化 URL
4. 当`发送消息`上方出现文档图标时，表示文档已成功加载

对于远程文档，您可以：
1. 在提示词前输入 `#` 加上文档 URL
2. 系统会自动将网页内容加载到工作区
3. 之后您就可以在对话中引用这些内容

## 网页内容集成

要在对话中使用网页内容：
1. 在聊天框中输入 `#` 后跟目标网页 URL
2. 点击聊天框上方显示的格式化 URL
3. 看到`发送消息`上方出现文档图标即表示加载成功
4. Open WebUI 会自动获取并解析网页内容

:::tip
提示：由于网页常包含导航栏、广告、页脚等干扰信息，建议使用页面的阅读模式或原始内容链接，这样可以获得更好的检索效果。
:::

## 功能配置与自定义

### RAG 模板定制
在`管理面板` > `设置` > `文档`中，您可以根据需求自定义 RAG 模板。

### 嵌入模型选择
支持 Ollama 和 OpenAI 的嵌入模型，可在`管理面板` > `设置` > `文档`中切换，以优化文档处理效果。

### 引用追踪
系统会自动为 LLM 使用的文档内容添加引用标记，确保信息来源可追溯，提高对话的可信度。

## 高级功能

### 混合搜索增强
- 采用 `BM25` 算法进行基础搜索
- 使用 `CrossEncoder` 技术进行结果重排序
- 支持自定义相关性分数阈值
- 可根据需求切换混合搜索功能

### YouTube 内容集成
- 支持直接处理 YouTube 视频 URL
- 自动提取和分析视频转录内容
- 将视频信息无缝整合到对话中

### 文档解析支持
系统配备多种解析器，可处理各类本地和远程文档。详细信息请参考 [`get_loader`](https://github.com/open-webui/open-webui/blob/2fa94956f4e500bf5c42263124c758d8613ee05e/backend/apps/rag/main.py#L328) 函数文档。

### Google Drive 集成
要启用 Google Drive 集成功能：
1. 确保您的 Google Cloud 项目已启用：
   - Google Picker API
   - Google Drive API
2. 在`管理面板` > `设置` > `文档`中开启此功能
3. 设置必要的环境变量：
   - `GOOGLE_DRIVE_API_KEY`
   - `GOOGLE_DRIVE_CLIENT_ID`
   
启用后，您可以：
- 直接从聊天界面访问 Drive 文件
- 上传各类文档（文档、幻灯片、表格等）
- 将文件内容用作对话上下文

详细配置说明请参考[环境变量配置文档](https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md)。
