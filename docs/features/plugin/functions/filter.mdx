---
sidebar_position: 2
title: "🪄 过滤器函数"
---

# 🪄 过滤器函数：修改输入和输出

欢迎阅读 Open WebUI 过滤器函数的综合指南！过滤器是一个灵活而强大的**插件系统**，用于修改*发送到大型语言模型（LLM）之前*（输入）或*从 LLM 返回之后*（输出）的数据。无论您是为了更好的上下文而转换输入，还是为了提高可读性而清理输出，**过滤器函数**都能让您完成所有这些工作。

本指南将分解**什么是过滤器**、它们如何工作、它们的结构，以及构建您自己的强大且用户友好的过滤器所需要知道的一切。让我们深入了解，别担心——我会使用比喻、示例和提示来让一切变得清晰明了！🌟

---

## 🌊 什么是 Open WebUI 中的过滤器？

想象 Open WebUI 是一条流经管道的**水流**：

- **用户输入**和**LLM 输出**是水。
- **过滤器**是在水到达最终目的地之前清洁、修改和调整水的**水处理阶段**。

过滤器位于流程的中间——像检查点一样——您可以在这里决定需要调整什么。

以下是过滤器功能的快速总结：

1. **修改用户输入（入口函数）**：在数据到达 AI 模型之前调整输入数据。这是您增强清晰度、添加上下文、净化文本或重新格式化消息以匹配特定要求的地方。
2. **修改模型输出（出口函数）**：在向用户显示之前调整 AI 的响应**处理后的结果**。这可以帮助完善、记录或调整数据，以获得更清晰的用户体验。

> **关键概念：**过滤器不是独立的模型，而是增强或转换*流向*和*来自*模型的数据的工具。

过滤器就像 AI 工作流中的**翻译者或编辑者**：您可以在不中断流程的情况下拦截和更改对话。

---

## 🗺️ 过滤器函数的结构：骨架

让我们从过滤器函数最简单的表示开始。如果一开始有些部分感觉很技术性，别担心——我们会一步一步地分解所有内容！

### 🦴 过滤器的基本骨架

```python
from pydantic import BaseModel
from typing import Optional

class Filter:
    # Valves：过滤器的配置选项
    class Valves(BaseModel):  
        pass

    def __init__(self):
        # 初始化阀门（过滤器的可选配置）
        self.valves = self.Valves()

    def inlet(self, body: dict) -> dict:
        # 这是您操作用户输入的地方。
        print(f"inlet called: {body}")
        return body  

    def outlet(self, body: dict) -> None:
        # 这是您操作模型输出的地方。
        print(f"outlet called: {body}")
```

---

### 🎯 关键组件解释

#### 1️⃣ **`Valves` 类（可选设置）**

将**阀门**视为过滤器的旋钮和滑块。如果您想给用户可配置的选项来调整过滤器的行为，您可以在这里定义它们。

```python
class Valves(BaseModel):
    OPTION_NAME: str = "默认值"
```

例如：
如果您正在创建一个将响应转换为大写的过滤器，您可以通过像 `TRANSFORM_UPPERCASE: bool = True/False` 这样的阀门允许用户配置是否将每个输出完全大写。

---

#### 2️⃣ **`inlet` 函数（输入预处理）**

`inlet` 函数就像**烹饪前的食材准备**。想象您是一位厨师：在食材进入食谱（在这种情况下是 LLM）之前，您可能需要洗菜、切洋葱或给肉调味。没有这一步，您的最终菜品可能缺乏风味、有未洗的农产品，或者简单地说不一致。

在 Open WebUI 的世界中，`inlet` 函数在将**用户输入**发送到模型之前执行这项重要的准备工作。它确保输入对 AI 来说尽可能清晰、有上下文和有帮助。

📥 **输入**：
- **`body`**：从 Open WebUI 到模型的原始输入。它采用聊天完成请求的格式（通常是一个包含对话消息、模型设置和其他元数据字段的字典）。把这想象成您的食谱配料。

🚀 **您的任务**：
修改并返回 `body`。修改后的 `body` 版本就是 LLM 使用的内容，所以这是您为输入带来清晰度、结构和上下文的机会。

##### 🍳 为什么要使用 `inlet`？
1. **添加上下文**：自动为用户的输入附加关键信息，特别是当他们的文本含糊或不完整时。例如，您可能会添加"您是一个友好的助手"或"帮助这个用户排除软件错误"。
   
2. **格式化数据**：如果输入需要特定格式，如 JSON 或 Markdown，您可以在发送到模型之前对其进行转换。

3. **净化输入**：删除不需要的字符，去除可能有害或令人困惑的符号（如多余的空格或表情符号），或替换敏感信息。

4. **简化用户输入**：如果您的模型输出可以通过额外的指导得到改善，您可以使用 `inlet` 自动注入澄清说明！

##### 💡 示例用例：基于食材准备
###### 🥗 示例 1：添加系统上下文
假设 LLM 是一位为意大利料理准备菜品的厨师，但用户没有提到"这是为了意大利烹饪"。您可以在将数据发送到模型之前通过附加此上下文来确保消息清晰。

```python
def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    # 在对话中添加意大利上下文的系统消息
    context_message = {
        "role": "system",
        "content": "您正在帮助用户准备意大利餐。"
    }
    # 在聊天历史开头插入上下文
    body.setdefault("messages", []).insert(0, context_message)
    return body
```

📖 **发生了什么？**
- 任何像"有什么好的晚餐主意？"这样的用户输入现在都带有意大利主题，因为我们设置了系统上下文！芝士蛋糕可能不会出现在答案中，但意大利面肯定会。

###### 🔪 示例 2：清理输入（删除奇怪的字符）
假设用户的输入看起来很乱或包含不需要的符号，如 `!!!`，这使得对话效率低下或模型更难解析。您可以在保留核心内容的同时清理它。

```python
def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    # 清理最后的用户输入（从'messages'列表的末尾）
    last_message = body["messages"][-1]["content"]
    body["messages"][-1]["content"] = last_message.replace("!!!", "").strip()
    return body
```

📖 **发生了什么？**
- 之前：`"我如何调试这个问题!!!"` ➡️ 发送给模型的是 `"我如何调试这个问题"`

注意：用户感觉是一样的，但模型处理的是更清晰、更容易理解的查询。

##### 📊 `inlet` 如何帮助优化 LLM 的输入：
- 通过澄清模糊的查询提高**准确性**。
- 通过删除不必要的噪音（如表情符号、HTML 标签或额外的标点符号）使 AI **更高效**。
- 通过将用户输入格式化以匹配模型的预期模式或模式（比如说，特定用例的 JSON）确保**一致性**。

💭 **将 `inlet` 视为您厨房中的副厨师**——确保进入模型（您的 AI"食谱"）的一切都已准备好、清洁并调味至完美。输入越好，输出就越好！

---

#### 3️⃣ **`outlet` 函数（输出后处理）**

`outlet` 函数就像一个**校对者**：在 AI 的响应*经过 LLM 处理后*整理（或进行最终更改）。

📤 **输入**：
- **`body`**：这包含聊天中的**所有当前消息**（用户历史 + LLM 回复）。

🚀 **您的任务**：修改这个 `body`。您可以清理、追加或记录更改，但要注意每个调整如何影响用户体验。

💡 **最佳实践**：
- 在出口中优先使用日志记录而不是直接编辑（例如，用于调试或分析）。
- 如果需要大量修改（如格式化输出），请考虑使用**管道函数**代替。

💡 **示例用例**：删除您不希望用户看到的敏感 API 响应：
```python
def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    for message in body["messages"]:
        message["content"] = message["content"].replace("<API_KEY>", "[已编辑]")
    return body 
```

---

## 🌟 过滤器实战：构建实用示例

让我们构建一些真实世界的示例，看看如何使用过滤器！

### 📚 示例 #1：为每个用户输入添加上下文

想让 LLM 始终知道它在帮助客户排除软件错误？您可以在每个用户查询中添加像**"您是软件故障排除助手"**这样的说明。

```python
class Filter:
    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        context_message = {
            "role": "system", 
            "content": "您是软件故障排除助手。"
        }
        body.setdefault("messages", []).insert(0, context_message)
        return body
```

---

### 📚 示例 #2：突出显示输出以便于阅读

要以 Markdown 或其他格式化样式返回输出？使用 `outlet` 函数！

```python
class Filter:
    def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # 为每个响应添加"突出显示"markdown
        for message in body["messages"]:
            if message["role"] == "assistant":  # 目标模型响应
                message["content"] = f"**{message['content']}**"  # 使用 Markdown 突出显示
        return body
```

---

## 🚧 潜在困惑：常见问题解答 🛑

### **问：过滤器与管道函数有什么不同？**

过滤器修改**流向**和**来自模型**的数据，但不会显著与这些阶段之外的逻辑交互。另一方面，管道：
- 可以集成**外部 API**或显著转换后端处理操作的方式。
- 将自定义逻辑公开为全新的"模型"。

### **问：我可以在 `outlet` 中进行大量后处理吗？**

您可以，但**这不是最佳实践**：
- **过滤器**设计用于进行轻量级更改或应用日志记录。
- 如果需要大量修改，请考虑使用**管道函数**代替。

---

## 🎉 回顾：为什么要构建过滤器函数？

到目前为止，您已经了解到：
1. **入口**操作**用户输入**（预处理）。
2. **出口**调整**AI 输出**（后处理）。
3. 过滤器最适合对数据流进行轻量级、实时的更改。
4. 通过**阀门**，您使用户能够动态配置过滤器以获得定制行为。

---

🚀 **轮到您了**：开始实验吧！什么样的小调整或上下文添加可以提升您的 Open WebUI 体验？过滤器构建起来很有趣，使用灵活，可以将您的模型提升到新的水平！

编码愉快！✨